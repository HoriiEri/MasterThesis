\chapter{結論}
\label{chap:conclusion}
本章では本論文の結論を述べ，今後の課題に言及する．

\section{まとめ}
本論文では，音源から演奏アニメーションを自動生成することにより，音源に同期したアニメーションを自動生成する手法を提案した．
音源は音情報を容易に解析できるMIDI音源を使用し，そこから得た遠走の情報をUnreal Engine のキャラクタに適用することにより，運指や表情が音源に同期した吹奏アニメーションを少ない時間，少ない労力で生成することができた．
特に音と1対1で対応する，トランペット奏者の指元や，トロンボーン奏者の腕の動きは，完全に音と同期した動きを再現できた．
複数人で演奏するアニメーションでは，それぞれの動きのパラメタを0から1で割り当てることにより，基となるモーションは1つであったが，演奏者全員に異なる動きを適用できた．

\section{今後の課題}
今後の課題としては，表情やモーションの種類の向上，モーションと音の関連付け，楽器や演奏者の増加が考えられる．
本節では各々について詳しく説明する．

\subsection{表情の豊かさの向上}
{\gt3.8.2項}で口元の制御について述べたが，演奏する際に動くのは口元だけではない．
他の演奏者と目配せを行うことや，音が長くて息継ぎできない場合や，音が高い場合は辛そうな表情をする．
楽器に息を入れる際に頬が膨らむ演奏者もいる．
なお，表情については個人差があるため，身体の動きと同様にパラメタをランダムで割り当て，動きの違いを表現する必要がある．

\subsection{モーションの種類の向上}
自動生成したアニメーションと，実際の演奏シーンと比較すると，キャラクタの動きに不自然な点が見つかる．
その原因の1つとして，モーションの種類が少ないことが挙げられる．
楽器を演奏する際の身体のモーションについては{\gt3.8.3項}で触れたが，ここで述べたモーションだけでは足りない．
例えば，音の高低に合わせて楽器を上下に揺らす演奏者や，円を描くように楽器を揺らす演奏者がいる．
これらのモーションを追加し，モーションの種類を増やすことにより，さまざまな表現の実現が可能になると考えられる．

\subsection{モーションと音の関連付け}
自動生成したアニメーションと，実際の演奏シーンと比較したときに，キャラクタの動きが不自然に見える原因として他に考えられるのが，モーションと音の関連付けが完璧でないことが挙げられる．
現在は，曲のテンポに従って身体が動く仕組みとなっており，モーションの種類や大きさは，ランダムに選択される仕様となっている．
音の遷移とモーションを1対1で対応させたり，モーションを事前に指定するためのメタデータを用意することにより，モーションと音を関連付ける必要がある．

\subsection{楽器の種類および演奏者の増加}
本論文では吹奏楽の1つの演奏形態である，少人数で演奏するアンサンブルを想定し，楽器はトランペットとトロンボーンを選択したが，アンサンブルで使用される楽器はこの2本だけではない．
また，将来的には吹奏楽のアニメーションの再現を目指す．
そのため，楽器のモデルを増やす必要がある．
それぞれの楽器に対応させるため，新たな実装を加える必要があるが，{\gt3.8.1項}の\tabref{tab:map}に示した音と運指の対応表を作成するだけで，トランペット，トロンボーンと同じように吹奏アニメーションの再現が可能となる．
また，今回は演奏者としてユニティちゃんを選択したが，演奏者それぞれの外見は異なっているべきである．
演奏者の外見が異なると，キャラクタの体型に差が出る．
体型に関わらず自然な吹奏アニメーションを生成するには，リターゲティングのための追加の実装や，動きの差を記述するメタデータが必要となる．